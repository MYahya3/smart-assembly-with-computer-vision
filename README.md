# ğŸ“ˆ Smart Assembly Line  using Computer Vision

This project showcases how computer vision can be used to **monitor and improve the efficiency of assembly line operations** using video analysis and object detection.

By leveraging a YOLO-based deep learning model, the system provides **real-time insights** into station usage, operator behavior, and overall productivityâ€”empowering manufacturers to make smarter, data-driven decisions.

---

<p align="center">
  <img src="https://github.com/user-attachments/assets/5d5f654e-d421-45b5-8201-800e10a679a7" alt="Assembly Line Monitoring Demo" width="600">
</p>

---

## ğŸš€ Features

- ğŸ¥ Analyze assembly line video footage (live or recorded)
- ğŸ§  Detect and track workers, stations, and machines using a trained YOLO model
- ğŸ“Š Automatically determine operational status across multiple stations
- ğŸ–¼ï¸ Overlay live status bars, timers, and ROI indicators on video output
- ğŸ’¾ Save annotated videos for reporting and review

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ main.py          # Core script to run monitoring on input videos
â”œâ”€â”€ utils.py         # Helper functions (ROIs, overlays, productivity logic)
â”œâ”€â”€ input/           # Folder to place input videos
â”œâ”€â”€ output/          # Folder where output videos are saved
â”œâ”€â”€ rois.json        # Stores selected Regions of Interest
â”œâ”€â”€ runs/            # YOLO model training outputs (best.pt file inside)
â””â”€â”€ README.md        # Project documentation
```

---

## ğŸ§© How It Works

1. ğŸ“¹ Provide an input video of the assembly line.
2. ğŸ” The system detects operators, stations, and machines using a trained YOLOv8 model.
3. ğŸ§  Logic interprets activity patterns to assess station performance.
4. ğŸ–¼ï¸ Visual overlays (status bars, labels, timers) are drawn on the video.
5. ğŸ“¤ The output is saved in the `output/` folder for review or reporting.

---

## âœ… Getting Started

### ğŸ”§ Requirements

- Python 3.8+
- Ultralytics YOLOv8
- OpenCV
- NumPy

Install dependencies:

```bash
pip install -r requirements.txt
```

---

### â–¶ï¸ How to Run

1. Add your input video to the `input/` folder.
2. Make sure the trained model is saved at:
   ```
   runs/detect/train/weights/best.pt
   ```
3. Run the script:

```bash
python main.py
```

4. On first run, select the Regions of Interest (ROIs) for monitoring stations.
5. The processed output video will be saved to:  
   ```
   output/demo_out.mp4
   ```

---

## ğŸ¯ Use Cases

- Monitor productivity and uptime of assembly line stations
- Detect worker-machine interaction and task completion
- Identify idle time, bottlenecks, or resource inefficiencies
- Generate annotated videos for analysis or operational audits

---

## ğŸ“„ License

This project is licensed under the **MIT License**.  
You're free to use, modify, and distribute it for personal or commercial purposes.

---

## ğŸ™‹â€â™‚ï¸ Contact

Feel free to reach out for questions, feedback, or collaboration opportunities!
